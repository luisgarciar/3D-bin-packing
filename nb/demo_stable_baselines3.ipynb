{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Using the StableBaselines3 library for reinforcement learning\n",
    "\n",
    "In this notebook we test an implementation of the proximal policy optimization (PPO)\n",
    "PPO is described in detail in https://arxiv.org/abs/1707.06347. It is a variant of Trust Region Policy Optimization (TRPO) described (in this paper )[https://arxiv.org/abs/1502.05477]. The PPO algorithm works in two phases. In one phase, a large number of rollouts are performed (in parallel). The rollouts are then aggregated on the driver and a surrogate optimization objective is defined based on those rollouts. We then use SGD to find the policy that maximizes that objective with a penalty term for diverging too much from the current policy.\n",
    "\n",
    "![ppo](https://raw.githubusercontent.com/ucbrise/risecamp/risecamp2018/ray/tutorial/rllib_exercises/ppo.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.envs import InvalidActionEnvDiscrete\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | 5.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 446      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 5.4          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 382          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046348795 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | -0.771       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.049       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0354      |\n",
      "|    value_loss           | 0.0633       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 6.02         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 380          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056301546 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | -0.045       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0472      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0449      |\n",
      "|    value_loss           | 0.0609       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x13881d100>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = InvalidActionEnvDiscrete(dim=80, n_invalid_actions=60)\n",
    "model = MaskablePPO(\"MlpPolicy\", env, gamma=0.4, seed=32, verbose=1)\n",
    "model.learn(5000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now test the PPO algorithm with the 3D bin packing environment."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from src.utils import boxes_generator\n",
    "from gym import make\n",
    "import warnings\n",
    "\n",
    "#Ignore plotly and gym deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#Environment initialization\n",
    "env = make(\n",
    "        \"PackingEnv-v0\",\n",
    "        container_size=[10, 10, 10],\n",
    "        box_sizes=boxes_generator([10, 10, 10], 64, 42),\n",
    "        num_visible_boxes=1,\n",
    "    )\n",
    "\n",
    "obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gym"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}